206 Final Review
================
final is in normal room
review wednesday 1pm in hill 005

1. Counting and Probability
    multi principle, combinations, bi- and multi-nom
2. Random Variables, expectation, variance
    definition, range, freq funciotn
    bernoulli, binomial, geometric, negative binomial freq functions
    expect and variance, definintions, computing,

3. Generating functions and applications
    gen functions
    gen func for a seq
    solving recurrence relations with gen fucntions

Counting
========
    multiplication principle
	# objects = # choices first * # choices second *...* #choices nth
    permutation
	ways to put n things in order = n!
	ways to put k out of n things in order: n! / (n-k)!
    permutation with repeats (r types)
	(n choose n1...nr)
    combinations
	ways to choose k out of n things order does not matter: (n! / k!(n-k)!) = (n choose k)
    partitions
	stars & bars
	#ways to divide n indistinguishable objects in r non empty piles (n-1) choose (r-1)
	#ways to divide n indistinguishable objects in r empty piles (n+r-1) choose (r-1)
	    trick: add r extra guys and remove them
    binomial thm
	from 0 to n ∑( (n choose k) x^k * y^n-k
	    why is this true?
    combinations identities
	from 0 to n ∑(n choose k) = 2^n
	(n choose k) = (n-1 choose k) + (n-1 choose k-1) [he glossed over this]
    multinomial thm
	how many terms in the sum? => this was on midterm 
	why is this true?

Basic Probability
=================

    Sample spaces and events
	sample spaces is a set S
	Events are subsets of S
	Intersection of E and F: "both E and F happen"
	union of E and F: "either E or F both happen"
	complement of E: "E does not happen"
	E and F are mutually exclusive if intersection of E and F is empty
    
    Probability Measure
	a prob measure is a fucntion P 

    Basic Identities
	P(ø) = 0
	P(E^c) = 1 - P(E)
	P(EuF) = P(E) + P(F) - P(E∏F)
    Uniform Prob Measure
	P(E) = |E|/|S|
    
    Conditional Probability
	P(E|F) = 

    Bayes' Thm
	e is "evidence", f is "outcome"
	[bayes thm]

    Multiplication Rule for Conditional Probability
	
	ex. P(set of two As)
	    = P(E1 ∏ E2) = P(E1) * P(E2|E1)
	    = 4/52 * 3/51

	... rest of midterm stuff

Random Variables
================
    Random Var
	formal: X is a r.v. means it is a function from a sample space to numbers
	intuitive: X is a way to randomly pick numbers (possibly not all with equal prob)

    You should be able to:
	give a random variable that describes a given experiemnt
	switch between intuitive and formal version of a random variable
	
    indicator R.V.s
	X = 1 means "a happened", 0 means "A didn't happen"

    Range, Partition, and Frequency Function
	Range(X) is every value that X can take
	Frequency function gives the probability that X takes each value in range:
	    Range(X) = {a1,..,ak}
	    Ai = { w is element of S : X(w) = ai}
	    Partitoin (X) = { A1, ..., Ak}
	    ƒ(x) 
    
    You should be able to:
	given an intitutive description of rv, find its range, partition, frequency function
	also formally

Expectation and Variance
========================
    Expectation
    -----------
	Weighted average of a random variable
	    E(X) = for all w in S ∑X(W)*P(W)
	    easier:
		E(X) = for all a in Range(X) ∑ ai * P(X=ai)
	
	You should be able to:
	    computer expectation of a random variable
    
    Linearity of Expectation
    ------------------------
	If X1,...,Xn are any random variables, then
	    E(X1+...+Xn) = E(X1) + ... + E(Xn)
	    E(aX+b) = aE(X)+b
	incredibly useful for computing expectation of complicated r.vs

    Using lineary of expectation
    ----------------------------
	To find E(X) for a complicated X
	1. Express X = X1+...+Xn for "simpler" X
	2. 
    fill these out ^

    You should be able to
    ---------------------
	Apply linearit of expectation
	understand how to break up a problem

    [some section
    ------


    Variance
    --------
	measure of 'swingyness' of a rand var
	    V(X) = E((X - E(X))^2) 
		squared to make positive
	easier to use
	    V(X) = (E(X^2))-E(X)^2
	    how to derive? linearity of expectation
	be careful computing E(X^2)

    Variance Formulas
    -----------------
	For any R.v.


    Covariance
    ----------
	measures how much X and Y swing together
	    if both go up together, +
	    if opposite, -
	for any X and Y,
	    Cov(X,Y) = E(
	easier:
	    Cov(X,Y) = E(XY) - E(X)E(Y)

    you should be able to
    ---
	compute variance of random variable (sometimes using 'linearity' trick)
	derive simple formula about variance

FOUR FUNCTIONS
==============
    Bernoulli: indicator for succes in 1 trial
    Binomial: # successes in n trials
    Geometric: # trials until first success
    negative binomial: # trial until k-th success

    binomial freq func
	if r.v. X has the binom freq fucntion with param

    geo freq func

    neg binomial freq func

    ok straight up what the fuck is all this shit

    should be able to:
	recognize freq func
	apply that knowledge to compute something

Two inequalities
================
    Markov's Inequality
	If X only takes non-negative values, then
	    P(X≥t) ≤ E(X) / t
    Chebycheff

    You hosuld be able to:
	recognize which inequality applies to a given situation
	apply te inequalities to given information
	derive simple consequences

Generating Functions
====================
    the gen fnction of a seq a1, a2, ... ,an
	A(X) = from 0 to ∞ ∑ an * x^n
	A generates a0, a1...

    operations on gen functions
	suppose A(X) is the gen fucn above
	xA(x) generates 0, a0, a1
	x^2A(x) gen 0,0,a0,a1

    convolutions
	if A(x) generates {ai} and B(x) generates {bi}, then A(x)B(x) generates {ci}

    Recurrence Relations
	given a recurrence relation definig an for all n, can find a formula for an
	technique:
	    let A(x) be generating fucntion for {an}
	    Find closed form of A(x)
	    use table to figure out series generated by A(x)
